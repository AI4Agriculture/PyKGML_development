{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d3607f-2a6a-41d0-af2f-b3ff761512c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from io import open\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import time\n",
    "from scipy.stats import gaussian_kde\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c61be5d-309e-4e5e-8e57-2e1db9b831ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Step2_DataSet\n",
    "from time_series_models import GRUSeq2SeqWithAttention, TimeSeriesModel, SequenceDataset\n",
    "# from sequence_dataset import SequenceDataset, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85a22384-3b41-4915-88bc-fc1953ce7d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kgml_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14931a18-f7ee-412c-97db-3826c7e1cabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions from kgml_lib\n",
    "Z_norm = kgml_lib.Z_norm \n",
    "Z_norm_reverse = kgml_lib.Z_norm_reverse\n",
    "get_gpu_memory = kgml_lib.get_gpu_memory\n",
    "# my_loss = kgml_lib.my_loss\n",
    "# compute_r2=kgml_lib.R2Loss()\n",
    "\n",
    "# myloss_mb_flux_mask = kgml_lib.myloss_mb_flux_mask\n",
    "# check_Rh2SOC_response = kgml_lib.check_Rh2SOC_response\n",
    "\n",
    "def stop_program():\n",
    "    raise SystemExit(\"Program terminated due to using CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b4bcac-0d31-4200-8b10-7e73288b67d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff4c5dc3-b488-4203-a046-3d1eebb0f862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6570, 100, 19]) torch.Size([6570, 100, 3]) torch.Size([18, 100, 1])\n",
      "['RADN', 'TMAX_AIR', 'TDIF_AIR', 'HMAX_AIR', 'HDIF_AIR', 'WIND', 'PRECN', 'Crop_Type', 'GPP', 'Year', 'TBKDS', 'TSAND', 'TSILT', 'TFC', 'TWP', 'TKSat', 'TSOC', 'TPH', 'TCEC']\n"
     ]
    }
   ],
   "source": [
    "root_dir = 'E:/PyKGML/deposit_code_v2/'\n",
    "data_path = root_dir +  'processed_data/'\n",
    "output_path = root_dir + 'test_results/'\n",
    "\n",
    "input_data = 'recotest_data_scaled_v4_100sample.sav'\n",
    "sample_index_file = \"traindataset_split_year_v1.sav\"\n",
    "\n",
    "pretrained_model = \"recotest_v11_exp4.sav_step1\"\n",
    "output_model = \"recotest_v11_exp4_sample.sav_step2\"\n",
    "synthetic_data = \"sys_data2.sav\"\n",
    "\n",
    "dataset = Step2_DataSet(data_path, input_data, output_path, sample_index_file)\n",
    "dataset.load_step2_data()\n",
    "\n",
    "dataset.prepare_step2_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77b23458-1f87-44ed-9226-472f20be2159",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input_features = 19\n",
    "num_output_features = 3\n",
    "\n",
    "input_dim = num_input_features\n",
    "hidden_dim = 128\n",
    "num_layers = 3\n",
    "output_dim = num_output_features\n",
    "dropout=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f93d1706-64fe-4fb5-ac8c-56c15e38b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one of the models below:\n",
    "#model = LSTMSeq2Seq(input_dim, hidden_dim, num_layers, output_dim)\n",
    "# model = GRUSeq2Seq(input_dim, hidden_dim, num_layers, output_dim)\n",
    "\n",
    "# model = EnhancedGRUModel(input_dim, hidden_dim, num_layers, output_dim)\n",
    "\n",
    "# model = GRUSeq2SeqWithAttention(input_dim, hidden_dim, num_layers, output_dim, dropout)\n",
    "\n",
    "model = GRUSeq2SeqWithAttention(input_dim, hidden_dim, num_layers, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5199f0c-6323-4c60-bbd3-1fff9f1a3ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.X  #[365*18, 100, 19]\n",
    "X = torch.transpose(X,1, 0) #[100, 365*18, 19]\n",
    "\n",
    "Y1 = dataset.Y1 #[365*18, 100, 3]\n",
    "Y1 = torch.transpose(Y1,1, 0) #[100, 365*18, 3]\n",
    "\n",
    "Y2 = dataset.Y2 #[18, 100, 1]\n",
    "Y2 = torch.transpose(Y2,1, 0)\n",
    "\n",
    "total_years = 18\n",
    "# days_per_year = 365\n",
    "# total_days = total_years * days_per_year\n",
    "# num_sites = X.shape[0] #100\n",
    "\n",
    "batch_size=64\n",
    "# train_loader, test_loader = model.train_test_split(X, Y1, batch_size)\n",
    "model.train_test_split(X, Y1, total_years, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c756d36f-a3e5-4abc-8554-75142aa3d937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60 | LR: 0.001000, Train Loss: 0.4554, Test Loss: 0.2034\n",
      "Epoch 2/60 | LR: 0.001000, Train Loss: 0.1688, Test Loss: 0.1358\n",
      "Epoch 3/60 | LR: 0.001000, Train Loss: 0.1311, Test Loss: 0.1140\n",
      "Epoch 4/60 | LR: 0.001000, Train Loss: 0.1095, Test Loss: 0.1020\n",
      "Epoch 5/60 | LR: 0.001000, Train Loss: 0.1018, Test Loss: 0.0951\n",
      "Epoch 6/60 | LR: 0.001000, Train Loss: 0.0911, Test Loss: 0.0874\n",
      "Epoch 7/60 | LR: 0.001000, Train Loss: 0.0889, Test Loss: 0.0795\n",
      "Epoch 8/60 | LR: 0.001000, Train Loss: 0.0816, Test Loss: 0.0778\n",
      "Epoch 9/60 | LR: 0.001000, Train Loss: 0.0825, Test Loss: 0.0765\n",
      "Epoch 10/60 | LR: 0.001000, Train Loss: 0.0756, Test Loss: 0.0714\n",
      "Epoch 11/60 | LR: 0.001000, Train Loss: 0.0714, Test Loss: 0.0728\n",
      "Epoch 12/60 | LR: 0.001000, Train Loss: 0.0716, Test Loss: 0.0687\n",
      "Epoch 13/60 | LR: 0.001000, Train Loss: 0.0706, Test Loss: 0.0670\n",
      "Epoch 14/60 | LR: 0.001000, Train Loss: 0.0665, Test Loss: 0.0628\n",
      "Epoch 15/60 | LR: 0.001000, Train Loss: 0.0649, Test Loss: 0.0634\n",
      "Epoch 16/60 | LR: 0.001000, Train Loss: 0.0663, Test Loss: 0.0656\n",
      "Epoch 17/60 | LR: 0.001000, Train Loss: 0.0625, Test Loss: 0.0598\n",
      "Epoch 18/60 | LR: 0.001000, Train Loss: 0.0604, Test Loss: 0.0595\n",
      "Epoch 19/60 | LR: 0.001000, Train Loss: 0.0591, Test Loss: 0.0585\n",
      "Epoch 20/60 | LR: 0.000800, Train Loss: 0.0574, Test Loss: 0.0552\n",
      "Epoch 21/60 | LR: 0.000800, Train Loss: 0.0570, Test Loss: 0.0587\n",
      "Epoch 22/60 | LR: 0.000800, Train Loss: 0.0558, Test Loss: 0.0583\n",
      "Epoch 23/60 | LR: 0.000800, Train Loss: 0.0542, Test Loss: 0.0566\n",
      "Epoch 24/60 | LR: 0.000800, Train Loss: 0.0530, Test Loss: 0.0613\n",
      "Epoch 25/60 | LR: 0.000800, Train Loss: 0.0538, Test Loss: 0.0538\n",
      "Epoch 26/60 | LR: 0.000800, Train Loss: 0.0512, Test Loss: 0.0549\n",
      "Epoch 27/60 | LR: 0.000800, Train Loss: 0.0503, Test Loss: 0.0572\n",
      "Epoch 28/60 | LR: 0.000800, Train Loss: 0.0507, Test Loss: 0.0540\n",
      "Epoch 29/60 | LR: 0.000800, Train Loss: 0.0506, Test Loss: 0.0581\n",
      "Epoch 30/60 | LR: 0.000800, Train Loss: 0.0497, Test Loss: 0.0542\n",
      "Epoch 31/60 | LR: 0.000800, Train Loss: 0.0492, Test Loss: 0.0593\n",
      "Epoch 32/60 | LR: 0.000800, Train Loss: 0.0539, Test Loss: 0.0557\n",
      "Epoch 33/60 | LR: 0.000800, Train Loss: 0.0485, Test Loss: 0.0520\n",
      "Epoch 34/60 | LR: 0.000800, Train Loss: 0.0466, Test Loss: 0.0553\n",
      "Epoch 35/60 | LR: 0.000800, Train Loss: 0.0496, Test Loss: 0.0609\n",
      "Epoch 36/60 | LR: 0.000800, Train Loss: 0.0486, Test Loss: 0.0511\n",
      "Epoch 37/60 | LR: 0.000800, Train Loss: 0.0467, Test Loss: 0.0557\n",
      "Epoch 38/60 | LR: 0.000800, Train Loss: 0.0474, Test Loss: 0.0552\n",
      "Epoch 39/60 | LR: 0.000800, Train Loss: 0.0451, Test Loss: 0.0514\n",
      "Epoch 40/60 | LR: 0.000640, Train Loss: 0.0449, Test Loss: 0.0568\n",
      "Epoch 41/60 | LR: 0.000640, Train Loss: 0.0445, Test Loss: 0.0524\n",
      "Epoch 42/60 | LR: 0.000640, Train Loss: 0.0452, Test Loss: 0.0535\n",
      "Epoch 43/60 | LR: 0.000640, Train Loss: 0.0432, Test Loss: 0.0498\n",
      "Epoch 44/60 | LR: 0.000640, Train Loss: 0.0423, Test Loss: 0.0516\n",
      "Epoch 45/60 | LR: 0.000640, Train Loss: 0.0416, Test Loss: 0.0483\n",
      "Epoch 46/60 | LR: 0.000640, Train Loss: 0.0406, Test Loss: 0.0493\n",
      "Epoch 47/60 | LR: 0.000640, Train Loss: 0.0405, Test Loss: 0.0512\n",
      "Epoch 48/60 | LR: 0.000640, Train Loss: 0.0411, Test Loss: 0.0455\n",
      "Epoch 49/60 | LR: 0.000640, Train Loss: 0.0405, Test Loss: 0.0471\n",
      "Epoch 50/60 | LR: 0.000640, Train Loss: 0.0398, Test Loss: 0.0469\n",
      "Epoch 51/60 | LR: 0.000640, Train Loss: 0.0395, Test Loss: 0.0500\n",
      "Epoch 52/60 | LR: 0.000640, Train Loss: 0.0394, Test Loss: 0.0452\n",
      "Epoch 53/60 | LR: 0.000640, Train Loss: 0.0397, Test Loss: 0.0523\n",
      "Epoch 54/60 | LR: 0.000640, Train Loss: 0.0404, Test Loss: 0.0453\n",
      "Epoch 55/60 | LR: 0.000640, Train Loss: 0.0389, Test Loss: 0.0495\n",
      "Epoch 56/60 | LR: 0.000640, Train Loss: 0.0384, Test Loss: 0.0458\n",
      "Epoch 57/60 | LR: 0.000640, Train Loss: 0.0377, Test Loss: 0.0467\n",
      "Epoch 58/60 | LR: 0.000640, Train Loss: 0.0379, Test Loss: 0.0491\n",
      "Epoch 59/60 | LR: 0.000640, Train Loss: 0.0380, Test Loss: 0.0442\n",
      "Epoch 60/60 | LR: 0.000512, Train Loss: 0.0372, Test Loss: 0.0452\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "step_size = 20\n",
    "max_epoch = 60\n",
    "\n",
    "# model.train_model(train_loader, test_loader, LR= learning_rate, step_size=20, gamma=0.8, maxepoch=60)\n",
    "model.train_model(LR= learning_rate, step_size= step_size, gamma=0.8, maxepoch=max_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f5fc225-0c6f-49ec-aa1c-6f92a3e78b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0452\n"
     ]
    }
   ],
   "source": [
    "# model.test(test_loader)\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1098cf07-a6ac-4338-8dc6-3118cd6bfa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_training_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d1ee73-8ea3-459d-a2c1-856cf15867df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
